# 1.1 Pytorch 简介

## 1.1.1 PyTorch的由来
很多人都会拿PyTorch和Google的Tensorflow进行比较，这个肯定是没有问题的，因为他们是最火的两个深度学习框架了。但是说到PyTorch，其实应该先说[Torch](http://torch.ch)。

## 1.1.2 Torch是什么？

**Torch英译中：火炬**
- Torch是一个与Numpy类似的张量（Tensor）操作库，与Numpy不同的是Torch对GPU支持的很好，Lua是Torch的上层包装。
- PyTorch和Torch使用包含所有相同性能的C库：TH, THC, THNN, THCUNN，并且它们将继续共享这些库。
- 其实PyTorch和Torch都使用的是相同的底层，只是使用了不同的上层包装语言。
- 注：LUA虽然快，但是太小众了，所以才会有PyTorch的出现。

## 1.1.3 重新介绍 PyTorch
PyTorch是一个基于Torch的Python开源机器学习库，用于自然语言处理等应用程序。 它主要由Facebook的人工智能研究小组开发。Uber的"Pyro"也是使用的这个库。

PyTorch是一个Python包，提供两个高级功能：
* 具有强大的GPU加速的张量计算（如NumPy）
* 包含自动求导系统的的深度神经网络

## 1.1.4 再次总结

- PyTorch算是相当简洁优雅且高效快速的框架
- 设计追求最少的封装，尽量避免重复造轮子
- 算是所有的框架中面向对象设计的最优雅的一个，设计最符合人们的思维，它让用户尽可能地专注于实现自己的想法
- 大佬支持,与google的Tensorflow类似，FAIR的支持足以确保PyTorch获得持续的开发更新
- 不错的的文档（相比FB的其他项目，PyTorch的文档简直算是完善了，参考Thrift），PyTorch作者亲自维护的论坛 供用户交流和求教问题
- 入门简单

## 1.1.5 PyTorch
基于Python的科学计算包，服务于以下两种场景:
-  作为NumPy的替代品，可以使用GPU的强大计算能力
-  提供最大的灵活性和高速的深度学习研究平台

## 1.1.6 PyTorch的用途
1. Tensors（张量）
- Tensors与Numpy中的 ndarrays类似
- Tensors 可以使用GPU进行计算.

>tensor([[0.0000, 0.0000, 0.0000],

>        [0.0000, 0.0000, 0.0000],

>        [0.0000, 0.0000, 0.0000],

>        [0.0000, 0.0000, 0.0000],

>        [0.0000, 0.0000, 0.0000]])

代码：x = torch.empty(5, 3)
        print(x)
 
>创建一个0填充的矩阵，数据类型为long:

x = torch.zeros(5, 3, dtype=torch.long)
print(x)
>创建tensor并使用现有数据初始化:

x = torch.tensor([5.5, 3])
print(x)
 
>根据现有的张量创建张量。 这些方法将重用输入张量的属性，例如， dtype，除非设置新的值进行覆盖

x = x.new_ones(5, 3, dtype=torch.double)      # new_* 方法来创建对象\n",
print(x)
x = torch.randn_like(x, dtype=torch.float)    # 覆盖 dtype!\n",
print(x)                                      #  对象的size 是相同的，只是值和类型发生了变化"
  
## NumPy 转换
将一个Torch Tensor转换为NumPy数组是一件轻松的事，反之亦然。

Torch Tensor与NumPy数组共享底层内存地址，修改一个会导致另一个的变化。

将一个Torch Tensor转换为NumPy数组

a = torch.ones(5)

print(a)

>tensor([1., 1., 1., 1., 1.])

b = a.numpy()

print(b)

>观察numpy数组的值是如何改变的

>[1., 1., 1., 1., 1.]

a.add_(1)

print(a)

>tensor([2., 2., 2., 2., 2.])

print(b)

**所有的 Tensor 类型默认都是基于CPU， CharTensor 类型不支持到 NumPy 的转换. CUDA 张量**